import copy

import pytest

from ray.autoscaler._private.aws.config import _get_vpc_id_or_die, \
    bootstrap_aws, log_to_cli, \
    DEFAULT_AMI
from ray.autoscaler._private.providers import _get_node_provider
import ray.tests.aws.utils.stubs as stubs
import ray.tests.aws.utils.helpers as helpers
from ray.tests.aws.utils.constants import AUX_SUBNET, DEFAULT_SUBNET, \
    DEFAULT_SG_AUX_SUBNET, DEFAULT_SG, DEFAULT_SG_DUAL_GROUP_RULES, \
    DEFAULT_SG_WITH_RULES_AUX_SUBNET, AUX_SG, \
    DEFAULT_SG_WITH_RULES, DEFAULT_SG_WITH_NAME, \
    DEFAULT_SG_WITH_NAME_AND_RULES, CUSTOM_IN_BOUND_RULES, \
    DEFAULT_KEY_PAIR, DEFAULT_INSTANCE_PROFILE, DEFAULT_CLUSTER_NAME, \
    DEFAULT_LT


def test_use_subnets_in_only_one_vpc(iam_client_stub, ec2_client_stub):
    """
    This test validates that when bootstrap_aws populates the SubnetIds field,
    all of the subnets used belong to the same VPC, and that a SecurityGroup
    in that VPC is correctly configured.

    Also validates that head IAM role is correctly filled.
    """
    stubs.configure_iam_role_default(iam_client_stub)
    stubs.configure_key_pair_default(ec2_client_stub)

    # Add a response with a thousand subnets all in different VPCs.
    # After filtering, only subnet in one particular VPC should remain.
    # Thus SubnetIds for each available node type should end up as
    # being length-one lists after the bootstrap_config.
    stubs.describe_a_thousand_subnets_in_different_vpcs(ec2_client_stub)

    # describe the subnet in use while determining its vpc
    stubs.describe_subnets_echo(ec2_client_stub, DEFAULT_SUBNET)
    # given no existing security groups within the VPC...
    stubs.describe_no_security_groups(ec2_client_stub)
    # expect to create a security group on the VPC
    stubs.create_sg_echo(ec2_client_stub, DEFAULT_SG)
    # expect new security group details to be retrieved after creation
    stubs.describe_sgs_on_vpc(
        ec2_client_stub,
        [DEFAULT_SUBNET["VpcId"]],
        [DEFAULT_SG],
    )

    # given no existing default security group inbound rules...
    # expect to authorize all default inbound rules
    stubs.authorize_sg_ingress(
        ec2_client_stub,
        DEFAULT_SG_WITH_RULES,
    )

    # expect another call to describe the above security group while checking
    # a second time if it has ip_permissions set ("if not sg.ip_permissions")
    stubs.describe_an_sg_2(
        ec2_client_stub,
        DEFAULT_SG_WITH_RULES,
    )

    # given our mocks and an example config file as input...
    # expect the config to be loaded, validated, and bootstrapped successfully
    config = helpers.bootstrap_aws_example_config_file("example-full.yaml")
    _get_vpc_id_or_die.cache_clear()

    # We've filtered down to only one subnet id -- only one of the thousand
    # subnets generated by ec2.subnets.all() belongs to the right VPC.
    for node_type in config["available_node_types"].values():
        node_config = node_type["node_config"]
        assert node_config["SubnetIds"] == [DEFAULT_SUBNET["SubnetId"]]
        assert node_config["SecurityGroupIds"] == [DEFAULT_SG["GroupId"]]


def test_create_sg_different_vpc_same_rules(iam_client_stub, ec2_client_stub):
    # use default stubs to skip ahead to security group configuration
    stubs.skip_to_configure_sg(ec2_client_stub, iam_client_stub)

    # given head and worker nodes with custom subnets defined...
    # expect to first describe the worker subnet ID
    stubs.describe_subnets_echo(ec2_client_stub, AUX_SUBNET)
    # expect to second describe the head subnet ID
    stubs.describe_subnets_echo(ec2_client_stub, DEFAULT_SUBNET)
    # given no existing security groups within the VPC...
    stubs.describe_no_security_groups(ec2_client_stub)
    # expect to first create a security group on the worker node VPC
    stubs.create_sg_echo(ec2_client_stub, DEFAULT_SG_AUX_SUBNET)
    # expect new worker security group details to be retrieved after creation
    stubs.describe_sgs_on_vpc(
        ec2_client_stub,
        [AUX_SUBNET["VpcId"]],
        [DEFAULT_SG_AUX_SUBNET],
    )
    # expect to second create a security group on the head node VPC
    stubs.create_sg_echo(ec2_client_stub, DEFAULT_SG)
    # expect new head security group details to be retrieved after creation
    stubs.describe_sgs_on_vpc(
        ec2_client_stub,
        [DEFAULT_SUBNET["VpcId"]],
        [DEFAULT_SG],
    )

    # given no existing default head security group inbound rules...
    # expect to authorize all default head inbound rules
    stubs.authorize_sg_ingress(
        ec2_client_stub,
        DEFAULT_SG_DUAL_GROUP_RULES,
    )
    # given no existing default worker security group inbound rules...
    # expect to authorize all default worker inbound rules
    stubs.authorize_sg_ingress(
        ec2_client_stub,
        DEFAULT_SG_WITH_RULES_AUX_SUBNET,
    )

    # given our mocks and an example config file as input...
    # expect the config to be loaded, validated, and bootstrapped successfully
    config = helpers.bootstrap_aws_example_config_file("example-subnets.yaml")

    # expect the bootstrapped config to show different head and worker security
    # groups residing on different subnets
    for node_type_key, node_type in config["available_node_types"].items():
        node_config = node_type["node_config"]
        security_group_ids = node_config["SecurityGroupIds"]
        subnet_ids = node_config["SubnetIds"]
        if node_type_key == config["head_node_type"]:
            assert security_group_ids == [DEFAULT_SG["GroupId"]]
            assert subnet_ids == [DEFAULT_SUBNET["SubnetId"]]
        else:
            assert security_group_ids == [AUX_SG["GroupId"]]
            assert subnet_ids == [AUX_SUBNET["SubnetId"]]

    # expect no pending responses left in IAM or EC2 client stub queues
    iam_client_stub.assert_no_pending_responses()
    ec2_client_stub.assert_no_pending_responses()


def test_create_sg_with_custom_inbound_rules_and_name(iam_client_stub,
                                                      ec2_client_stub):
    # use default stubs to skip ahead to security group configuration
    stubs.skip_to_configure_sg(ec2_client_stub, iam_client_stub)

    # expect to describe the head subnet ID
    stubs.describe_subnets_echo(ec2_client_stub, DEFAULT_SUBNET)
    # given no existing security groups within the VPC...
    stubs.describe_no_security_groups(ec2_client_stub)
    # expect to create a security group on the head node VPC
    stubs.create_sg_echo(ec2_client_stub, DEFAULT_SG_WITH_NAME)
    # expect new head security group details to be retrieved after creation
    stubs.describe_sgs_on_vpc(
        ec2_client_stub,
        [DEFAULT_SUBNET["VpcId"]],
        [DEFAULT_SG_WITH_NAME],
    )

    # given custom existing default head security group inbound rules...
    # expect to authorize both default and custom inbound rules
    stubs.authorize_sg_ingress(
        ec2_client_stub,
        DEFAULT_SG_WITH_NAME_AND_RULES,
    )

    # given the prior modification to the head security group...
    # expect the next read of a head security group property to reload it
    stubs.describe_sg_echo(ec2_client_stub, DEFAULT_SG_WITH_NAME_AND_RULES)

    _get_vpc_id_or_die.cache_clear()
    # given our mocks and an example config file as input...
    # expect the config to be loaded, validated, and bootstrapped successfully
    config = helpers.bootstrap_aws_example_config_file(
        "example-security-group.yaml")

    # expect the bootstrapped config to have the custom security group...
    # name and in bound rules
    assert config["provider"]["security_group"][
        "GroupName"] == DEFAULT_SG_WITH_NAME_AND_RULES["GroupName"]
    assert config["provider"]["security_group"][
        "IpPermissions"] == CUSTOM_IN_BOUND_RULES

    # expect no pending responses left in IAM or EC2 client stub queues
    iam_client_stub.assert_no_pending_responses()
    ec2_client_stub.assert_no_pending_responses()


def test_cloudwatch_dashboard_creation(cloudwatch_client_stub,
                                       ssm_client_stub):
    # create test cluster node IDs and an associated cloudwatch helper
    node_id = "i-abc"
    cloudwatch_helper = helpers.get_cloudwatch_helper(node_id)

    # given a directive to create a cluster CloudWatch Dashboard...
    # expect to make a call to create a dashboard for each node in the cluster
    stubs.put_cluster_dashboard_success(
        cloudwatch_client_stub,
        cloudwatch_helper,
    )

    # given our mocks and the example CloudWatch Dashboard config as input...
    # expect a cluster CloudWatch Dashboard to be created successfully
    cloudwatch_helper._put_cloudwatch_dashboard()
    # expect no pending responses left in the CloudWatch client stub queue
    cloudwatch_client_stub.assert_no_pending_responses()


def test_cloudwatch_alarm_creation(cloudwatch_client_stub, ssm_client_stub):
    # create test cluster node IDs and an associated cloudwatch helper
    node_id = "i-abc"
    cloudwatch_helper = helpers.get_cloudwatch_helper(node_id)

    # given a directive to update a cluster CloudWatch Alarm Config without any
    # change...
    # expect the stored the CloudWatch Alarm Config is same as local config
    cw_ssm_param_name = helpers.get_ssm_param_name(
        cloudwatch_helper.cluster_name, "alarm")
    stubs.get_param_ssm_same(ssm_client_stub, cw_ssm_param_name,
                             cloudwatch_helper, "alarm")

    # given a directive to create cluster CloudWatch alarms...
    # expect to make a call to create alarms for each node in the cluster
    stubs.put_cluster_alarms_success(cloudwatch_client_stub, cloudwatch_helper)

    # given our mocks and the example CloudWatch Alarm config as input...
    # expect cluster alarms to be created successfully
    cloudwatch_helper._put_cloudwatch_alarm()

    # expect no pending responses left in the CloudWatch client stub queue
    cloudwatch_client_stub.assert_no_pending_responses()


def test_cloudwatch_agent_update_without_change_head_node(
        ssm_client_stub, ec2_client_stub):
    # create test cluster head node ID and an associated cloudwatch helper
    node_id = "i-abc"
    is_head_node = True
    cloudwatch_helper = helpers.get_cloudwatch_helper(node_id)

    # given a directive to check for the Unified CloudWatch Agent status...
    # expect CloudWatch Agent is installed
    stubs.get_ec2_cwa_installed_tag_true(ec2_client_stub, node_id)

    # given a directive to update a cluster CloudWatch Agent Config without any
    # change...
    # expect the stored the CloudWatch Agent Config is same as local config
    cw_ssm_param_name = helpers.get_ssm_param_name(
        cloudwatch_helper.cluster_name, "agent")
    stubs.get_param_ssm_same(ssm_client_stub, cw_ssm_param_name,
                             cloudwatch_helper, "agent")

    # given our mocks and the same cloudwatch agent config as input...
    # expect no update performed on CloudWatch Agent Config
    cloudwatch_helper._update_cloudwatch_config("agent", is_head_node)


def test_cloudwatch_agent_update_with_change_head_node(ec2_client_stub,
                                                       ssm_client_stub):
    # create test cluster head node ID and an associated cloudwatch helper
    node_id = "i-abc"
    is_head_node = True
    cloudwatch_helper = helpers.get_cloudwatch_helper(node_id)

    # given a directive to check for the Unified CloudWatch Agent status...
    # expect CloudWatch Agent is installed
    stubs.get_ec2_cwa_installed_tag_true(ec2_client_stub, node_id)
    # given a directive to update a cluster CloudWatch Agent Config with new
    # changes...
    # expect the stored the CloudWatch Agent Config is different from local
    # config
    cw_ssm_param_name = helpers.get_ssm_param_name(
        cloudwatch_helper.cluster_name, "agent")
    stubs.get_param_ssm_different(ssm_client_stub, cw_ssm_param_name)

    # given an updated CloudWatch Agent Config file...
    # expect to store the new CloudWatch Agent config as an SSM parameter
    cmd_id = stubs.put_parameter_cloudwatch_config(
        ssm_client_stub, cloudwatch_helper.cluster_name, "agent")

    # given an updated CloudWatch Agent Config file...
    # expect to update the node tag equal to updated config file sha1 hash
    # to reflect the changes in config file
    stubs.update_hash_tag_success(ec2_client_stub, node_id, "agent",
                                  cloudwatch_helper)
    # given that updated CloudWatch Agent Config is put to Parameter Store...
    # expect to send an SSM command to restart CloudWatch Agent on all nodes
    cmd_id = stubs.send_command_stop_cwa(ssm_client_stub, node_id)
    # given a SSM command to stop CloudWatch Agent sent to all nodes...
    # expect to wait for the command to complete successfully on every node
    stubs.list_command_invocations_success(ssm_client_stub, node_id, cmd_id)
    cmd_id = stubs.send_command_start_cwa(ssm_client_stub, node_id,
                                          cw_ssm_param_name)
    # given a SSM command to start CloudWatch Agent sent to all nodes...
    # expect to wait for the command to complete successfully on every node
    stubs.list_command_invocations_success(ssm_client_stub, node_id, cmd_id)

    # given our mocks and the example CloudWatch Agent config as input...
    # expect CloudWatch Agent configured to use updated file on each cluster
    # node successfully
    cloudwatch_helper._update_cloudwatch_config("agent", is_head_node)

    # expect no pending responses left in client stub queues
    ec2_client_stub.assert_no_pending_responses()
    ssm_client_stub.assert_no_pending_responses()


def test_cloudwatch_agent_update_with_change_worker_node(
        ec2_client_stub, ssm_client_stub):
    # create test cluster worker node ID and an associated cloudwatch helper
    node_id = "i-abc"
    is_head_node = False
    cloudwatch_helper = helpers.get_cloudwatch_helper(node_id)

    # given a directive to check for the Unified CloudWatch Agent status...
    # expect CloudWatch Agent is installed
    stubs.get_ec2_cwa_installed_tag_true(ec2_client_stub, node_id)

    # given a directive to update a cluster CloudWatch Agent Config with new
    # changes...
    # expect the stored the CloudWatch Agent Config is different from local
    # config
    stubs.get_head_node_config_hash_different(ec2_client_stub, "agent",
                                              cloudwatch_helper, node_id)
    stubs.get_cur_node_config_hash_different(ec2_client_stub, "agent", node_id)

    # given an updated CloudWatch Agent Config file...
    # expect to update the node tag equal to updated config file sha1 hash
    # to reflect the changes in config file
    stubs.update_hash_tag_success(ec2_client_stub, node_id, "agent",
                                  cloudwatch_helper)
    # given that updated CloudWatch Agent Config is put to Parameter Store...
    # expect to send an SSM command to restart CloudWatch Agent on all nodes
    cmd_id = stubs.send_command_stop_cwa(ssm_client_stub, node_id)
    # given a SSM command to stop CloudWatch Agent sent to all nodes...
    # expect to wait for the command to complete successfully on every node
    stubs.list_command_invocations_success(ssm_client_stub, node_id, cmd_id)
    cw_ssm_param_name = helpers.get_ssm_param_name(
        cloudwatch_helper.cluster_name, "agent")
    cmd_id = stubs.send_command_start_cwa(ssm_client_stub, node_id,
                                          cw_ssm_param_name)
    # given a SSM command to start CloudWatch Agent sent to all nodes...
    # expect to wait for the command to complete successfully on every node
    stubs.list_command_invocations_success(ssm_client_stub, node_id, cmd_id)

    # given our mocks and the example CloudWatch Agent config as input...
    # expect CloudWatch Agent configured to use updated file on each cluster
    # node successfully
    cloudwatch_helper._update_cloudwatch_config("agent", is_head_node)

    # expect no pending responses left in client stub queues
    ec2_client_stub.assert_no_pending_responses()
    ssm_client_stub.assert_no_pending_responses()


def test_cloudwatch_dashboard_update_head_node(
        ec2_client_stub, ssm_client_stub, cloudwatch_client_stub):
    # create test cluster head node ID and an associated cloudwatch helper
    node_id = "i-abc"
    is_head_node = True
    cloudwatch_helper = helpers.get_cloudwatch_helper(node_id)

    # given a directive to check for the Unified CloudWatch Agent status...
    # expect CloudWatch Agent is installed
    stubs.get_ec2_cwa_installed_tag_true(ec2_client_stub, node_id)

    # given a directive to update a cluster CloudWatch Dashboard Config
    # with new changes...
    # expect the stored the CloudWatch Dashboard Config is different from local
    # config
    cw_ssm_param_name = helpers.get_ssm_param_name(
        cloudwatch_helper.cluster_name, "dashboard")
    stubs.get_param_ssm_different(ssm_client_stub, cw_ssm_param_name)

    # given an updated CloudWatch Dashboard Config file...
    # expect to store the new CloudWatch Dashboard config as an SSM parameter
    stubs.put_parameter_cloudwatch_config(
        ssm_client_stub, cloudwatch_helper.cluster_name, "dashboard")

    # given an updated CloudWatch Dashboard Config file...
    # expect to update the node tag equal to updated config file sha1 hash
    # to reflect the changes in config file
    stubs.update_hash_tag_success(ec2_client_stub, node_id, "dashboard",
                                  cloudwatch_helper)

    # given a directive to create a cluster CloudWatch dashboard...
    # expect to make a call to create a dashboard for each node in the cluster
    stubs.put_cluster_dashboard_success(
        cloudwatch_client_stub,
        cloudwatch_helper,
    )
    # given our mocks and the example CloudWatch Dashboard config as input...
    # expect CloudWatch Dashboard configured to use updated file
    # on each cluster node successfully
    cloudwatch_helper._update_cloudwatch_config("dashboard", is_head_node)

    # expect no pending responses left in client stub queues
    ec2_client_stub.assert_no_pending_responses()
    ssm_client_stub.assert_no_pending_responses()


def test_cloudwatch_dashboard_update_worker_node(
        ec2_client_stub, ssm_client_stub, cloudwatch_client_stub):
    # create test cluster worker node ID and an associated cloudwatch helper
    node_id = "i-abc"
    is_head_node = False
    cloudwatch_helper = helpers.get_cloudwatch_helper(node_id)

    # given a directive to check for the Unified CloudWatch Agent status...
    # expect CloudWatch Agent is installed
    stubs.get_ec2_cwa_installed_tag_true(ec2_client_stub, node_id)

    # given a directive to update a cluster CloudWatch Dashboard Config
    # with new changes...
    # expect the stored the CloudWatch Dashboard Config is different from local
    # config
    stubs.get_head_node_config_hash_different(ec2_client_stub, "dashboard",
                                              cloudwatch_helper, node_id)
    stubs.get_cur_node_config_hash_different(ec2_client_stub, "dashboard",
                                             node_id)

    # given an updated CloudWatch Dashboard Config file...
    # expect to update the node tag equal to updated config file sha1 hash
    # to reflect the changes in config file
    stubs.update_hash_tag_success(ec2_client_stub, node_id, "dashboard",
                                  cloudwatch_helper)

    # given our mocks and the example CloudWatch Dashboard config as input...
    # expect CloudWatch Dashboard configured to use updated file
    # on each cluster node successfully
    cloudwatch_helper._update_cloudwatch_config("dashboard", is_head_node)

    # expect no pending responses left in client stub queues
    ec2_client_stub.assert_no_pending_responses()
    ssm_client_stub.assert_no_pending_responses()


def test_cloudwatch_alarm_update_head_node(ec2_client_stub, ssm_client_stub,
                                           cloudwatch_client_stub):
    # create test cluster head node ID and an associated cloudwatch helper
    node_id = "i-abc"
    is_head_node = True
    cloudwatch_helper = helpers.get_cloudwatch_helper(node_id)

    # given a directive to check for the Unified CloudWatch Agent status...
    # expect CloudWatch Agent is installed
    stubs.get_ec2_cwa_installed_tag_true(ec2_client_stub, node_id)

    # given a directive to update a cluster CloudWatch Alarm Config with new
    # changes...
    # expect the stored the CloudWatch Alarm Config is different from local
    # config
    cw_ssm_param_name = helpers.get_ssm_param_name(
        cloudwatch_helper.cluster_name, "alarm")
    stubs.get_param_ssm_different(ssm_client_stub, cw_ssm_param_name)

    # given an updated CloudWatch Alarm Config file...
    # expect to store the new CloudWatch Alarm config as an SSM parameter
    stubs.put_parameter_cloudwatch_config(
        ssm_client_stub, cloudwatch_helper.cluster_name, "alarm")

    # given an updated CloudWatch Alarm Config file...
    # expect to update the node tag equal to updated config file sha1 hash
    # to reflect the changes in config file
    stubs.update_hash_tag_success(ec2_client_stub, node_id, "alarm",
                                  cloudwatch_helper)
    stubs.get_param_ssm_same(ssm_client_stub, cw_ssm_param_name,
                             cloudwatch_helper, "alarm")

    # given a directive to create cluster  CloudWatch Alarms...
    # expect to make a call to create alarms for each node in the cluster
    stubs.put_cluster_alarms_success(cloudwatch_client_stub, cloudwatch_helper)

    # given our mocks and the example  CloudWatch Alarm config as input...
    # expect  CloudWatch Alarm configured to use updated file on each cluster
    # node successfully
    cloudwatch_helper._update_cloudwatch_config("alarm", is_head_node)

    # expect no pending responses left in client stub queues
    ec2_client_stub.assert_no_pending_responses()
    ssm_client_stub.assert_no_pending_responses()


def test_cloudwatch_alarm_update_worker_node(ec2_client_stub, ssm_client_stub,
                                             cloudwatch_client_stub):
    # create test cluster worker node ID and an associated cloudwatch helper
    node_id = "i-abc"
    is_head_node = False
    cloudwatch_helper = helpers.get_cloudwatch_helper(node_id)

    # given a directive to check for the Unified CloudWatch Agent status...
    # expect CloudWatch Agent is installed
    stubs.get_ec2_cwa_installed_tag_true(ec2_client_stub, node_id)

    # given a directive to update a cluster CloudWatch Alarm Config with new
    # changes...
    # expect the stored the CloudWatch Alarm Config is different from local
    # config
    cw_ssm_param_name = helpers.get_ssm_param_name(
        cloudwatch_helper.cluster_name, "alarm")

    # given a directive to update a cluster CloudWatch Alarm Config with new
    # changes...
    # expect the stored the CloudWatch Alarm Config is different from local
    # config
    stubs.get_head_node_config_hash_different(ec2_client_stub, "alarm",
                                              cloudwatch_helper, node_id)
    stubs.get_cur_node_config_hash_different(ec2_client_stub, "alarm", node_id)

    # given an updated CloudWatch Alarm Config file...
    # expect to update the node tag equal to updated config file sha1 hash
    # to reflect the changes in config file
    stubs.update_hash_tag_success(ec2_client_stub, node_id, "alarm",
                                  cloudwatch_helper)
    stubs.get_param_ssm_same(ssm_client_stub, cw_ssm_param_name,
                             cloudwatch_helper, "alarm")

    # given a directive to create cluster CloudWatch Alarms...
    # expect to make a call to create alarms for each node in the cluster
    stubs.put_cluster_alarms_success(cloudwatch_client_stub, cloudwatch_helper)
    # given our mocks and the example CloudWatch Alarm config as input...
    # expect CloudWatch Alarm configured to use updated file on each cluster
    # node successfully
    cloudwatch_helper._update_cloudwatch_config("alarm", is_head_node)

    # expect no pending responses left in client stub queues
    ec2_client_stub.assert_no_pending_responses()
    ssm_client_stub.assert_no_pending_responses()


if __name__ == "__main__":
    import sys
    sys.exit(pytest.main(["-v", __file__]))
